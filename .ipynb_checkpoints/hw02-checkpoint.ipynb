{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 158/258, Fall 2020: Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Please submit your solution **by the beginning of the week 5 lecture (Nov 2)**. Submissions should be\n",
    "made on **gradescope**. Please complete homework **individually**.\n",
    "\n",
    "This specification includes both questions from the undergraduate (CSE158) and graduate (CSE258) classes.\n",
    "You are welcome to attempt questions from both classes but will only be graded on those for the class in which\n",
    "you are enrolled.\n",
    "\n",
    "You will need the following files:\n",
    "\n",
    "**Beer Reviews** : https://cseweb.ucsd.edu/classes/fa20/cse258-a/data/beer_50000.json\n",
    "\n",
    "**Facebook ego network** : https://cseweb.ucsd.edu/classes/fa20/cse258-a/data/egonet.txt.\n",
    "\n",
    "**Code examples** : http://cseweb.ucsd.edu/classes/fa19/cse258-a/code/week2.py (classification) and\n",
    "http://cseweb.ucsd.edu/classes/fa19/cse258-a/code/week3.py (clustering/communities)\n",
    "\n",
    "Executing the code requires a working install of Python 2.7 or Python 3 with the scipy packages installed.\n",
    "**Please include the code of (the important parts of) your solutions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Written in python 3\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "import ast\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn import linear_model, metrics\n",
    "import gzip\n",
    "import re\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_url = 'https://cseweb.ucsd.edu/classes/fa20/cse258-a/data/beer_50000.json'\n",
    "fb_url = 'https://cseweb.ucsd.edu/classes/fa20/cse258-a/data/egonet.txt'\n",
    "ex1_url = 'http://cseweb.ucsd.edu/classes/fa19/cse258-a/code/week2.py'\n",
    "ex2_url = 'http://cseweb.ucsd.edu/classes/fa19/cse258-a/code/week3.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gSave(url, path, filename):\n",
    "    r = requests.get(url) #request url\n",
    "    open(os.path.join(path, filename), 'wb').write(r.content) #save file in path\n",
    "\n",
    "def parseData(fname, dataset = []):\n",
    "    print('Reading data from', fname,'...')\n",
    "    \n",
    "    if re.search(r'\\.gz$', fname):\n",
    "        for line in gzip.open(fname, 'rt', errors = 'ignore'):\n",
    "            yield ast.literal_eval(line)\n",
    "        print('Done!')\n",
    "\n",
    "    else:\n",
    "        for l in open(fname):\n",
    "            yield ast.literal_eval(l)\n",
    "        print('Done')\n",
    "        \n",
    "def getData(src, dst):\n",
    "    try:\n",
    "            gSave(url = src, \n",
    "              path = dst,\n",
    "              filename = src.split('/')[-1])\n",
    "    except FileNotFoundError as e:\n",
    "        os.mkdir(dst)\n",
    "        gSave(url = src, \n",
    "              path = dst,\n",
    "              filename = src.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'data'\n",
    "getData(beer_url, fp)\n",
    "getData(fb_url, fp)\n",
    "\n",
    "fp = 'examples'\n",
    "getData(ex1_url, fp)\n",
    "getData(ex2_url, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks — Diagnostics (week 2):\n",
    "\n",
    "We’ll start by building a classifier that predicts whether a beer is highly alcoholic (ABV greater than 7 percent).\n",
    "First, randomly shuffle the data and split it into 50%/50% train/test fractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from data/beer_50000.json ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "fp = os.path.join('data', 'beer_50000.json')\n",
    "beer = list(parseData(fp))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'review/appearance': 2.5,\n",
       "  'beer/style': 'Hefeweizen',\n",
       "  'review/palate': 1.5,\n",
       "  'review/taste': 1.5,\n",
       "  'beer/name': 'Sausa Weizen',\n",
       "  'review/timeUnix': 1234817823,\n",
       "  'beer/ABV': 5.0,\n",
       "  'beer/beerId': '47986',\n",
       "  'beer/brewerId': '10325',\n",
       "  'review/timeStruct': {'isdst': 0,\n",
       "   'mday': 16,\n",
       "   'hour': 20,\n",
       "   'min': 57,\n",
       "   'sec': 3,\n",
       "   'mon': 2,\n",
       "   'year': 2009,\n",
       "   'yday': 47,\n",
       "   'wday': 0},\n",
       "  'review/overall': 1.5,\n",
       "  'review/text': 'A lot of foam. But a lot.\\tIn the smell some banana, and then lactic and tart. Not a good start.\\tQuite dark orange in color, with a lively carbonation (now visible, under the foam).\\tAgain tending to lactic sourness.\\tSame for the taste. With some yeast and banana.',\n",
       "  'user/profileName': 'stcules',\n",
       "  'review/aroma': 2.0},\n",
       " 50000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first element to get an idea of the data features\n",
    "beer[0], len(beer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We’ll use the *style* of the beer to predict its ABV. Construct a one-hot encoding of the beer style, for\n",
    "those categories that appear in more than 1,000 reviews. You can build a mapping of categories to feature\n",
    "indices as follows:\n",
    "\n",
    "<code id = block>\n",
    "    categoryCounts = defaultdict(int)\n",
    "    for d in data:\n",
    "        categoryCounts[d['beer/style']] += 1<br />\n",
    "    categories = [c for c in categoryCounts if categoryCounts[c] > 1000]\n",
    "    catID = dict(zip(list(categories),range(len(categories))))\n",
    "</code>\n",
    "<br />\n",
    "\n",
    "Train a logistic regressor using this one-hot encoding to predict whether beers have an ABV greater than\n",
    "7 percent (i.e., `d['beer/ABV'] > 7`). Train the classifier on the training set and report its performance\n",
    "in terms of the accuracy and Balanced Error Rate (BER) on the test set, using a regularization constant\n",
    "of $C = 10$. For all experiments use the `class_weight='balanced'` option (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'American Double / Imperial IPA': '0',\n",
       " 'Rauchbier': '1',\n",
       " 'American Pale Ale (APA)': '2',\n",
       " 'American Porter': '3',\n",
       " 'Russian Imperial Stout': '4',\n",
       " 'American IPA': '5',\n",
       " 'Fruit / Vegetable Beer': '6',\n",
       " 'American Double / Imperial Stout': '7',\n",
       " 'Rye Beer': '8',\n",
       " 'Scotch Ale / Wee Heavy': '9',\n",
       " 'English Pale Ale': '10',\n",
       " 'Czech Pilsener': '11',\n",
       " 'Old Ale': '12'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer_styles = [b['beer/style'] for b in beer if 'beer/style' in b]\n",
    "categoryCounts = dict(zip(beer_styles, np.zeros(len(beer_styles))))\n",
    "\n",
    "for b in beer:\n",
    "    categoryCounts[b['beer/style']] += 1\n",
    "        \n",
    "\n",
    "categories = [c for c in categoryCounts if categoryCounts[c] > 1000]\n",
    "catID = np.array(list(zip(list(categories),range(len(categories)))))\n",
    "catID_dict = dict(catID)\n",
    "catID_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [b['beer/style'] for b in beer if b['beer/style'] in catID]\n",
    "y = [b['beer/ABV'] > 7 for b in beer if b['beer/style'] in catID]\n",
    "\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "X = ohe.fit_transform(np.array(X).reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 1/3)\n",
    "logre = linear_model.LogisticRegression(C = 10, \n",
    "                                        class_weight = 'balanced')\n",
    "preds = logre.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True, False,  True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False,  True, False])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(y_pred, y_actual, to_print = True):\n",
    "    tprate = sum((y_pred == True) == y_actual)/sum(y_pred)\n",
    "    if to_print:\n",
    "        print('Calculated a TPR of %f%%' % (tprate))\n",
    "    return tprate\n",
    "\n",
    "def fpr(y_pred, y_actual, to_print = True):\n",
    "    fprate = sum((y_pred == False) == y_actual)/sum(y_pred == False)\n",
    "    if to_print:\n",
    "        print('Calculated a FPR of %f%%' % (fprate))\n",
    "    return fprate\n",
    "    \n",
    "def ber(y_pred, y_actual):\n",
    "    berate = 1 - (0.5 * (tpr(y_pred, y_actual, False) + fpr(y_pred, y_actual, False)))\n",
    "    display_msg=('Using logistic regression on the One Hot Encoded beer styles to predict a beer ' +\n",
    "                 'ABV avove 7.0%%, I predicted the\\nBER to be  %f' % berate)\n",
    "    print(display_msg)\n",
    "    return berate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using logistic regression on the One Hot Encoded beer styles to predict a beer ABV avove 7.0%, I predicted the \n",
      "accuracy to be  0.930928\n"
     ]
    }
   ],
   "source": [
    "accuracy = logre.score(x_test, y_test)\n",
    "display_msg = ('Using logistic regression on the One Hot Encoded beer styles to predict a beer ABV avove 7.0%, '+\n",
    "               f'I predicted the \\naccuracy to be  %f' % accuracy)\n",
    "print(display_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10971</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10972</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10973</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_test  prediction\n",
       "0        True        True\n",
       "1       False       False\n",
       "2        True        True\n",
       "3        True        True\n",
       "4       False       False\n",
       "...       ...         ...\n",
       "10969    True        True\n",
       "10970   False       False\n",
       "10971    True        True\n",
       "10972    True       False\n",
       "10973    True        True\n",
       "\n",
       "[10974 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated a TPR of 1.861177%\n",
      "Calculated a FPR of 0.138195%\n",
      "Using logistic regression on the One Hot Encoded beer styles to predict a beer ABV avove 7.0%, I predicted the\n",
      "BER to be  0.000314\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>ber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.861177</td>\n",
       "      <td>0.138195</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tpr       fpr       ber\n",
       "0  1.861177  0.138195  0.000314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame({'y_test':y_test,\n",
    "                              'prediction':preds}))\n",
    "display(pd.DataFrame({'tpr':[tpr(preds, y_test)],\n",
    "                      'fpr':[fpr(preds, y_test)],\n",
    "                      'ber':[ber(preds, y_test)]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Extend your model to include two additional features: <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1) a vector of five ratings (`review/aroma`,\n",
    "`review/overall`, etc.); and <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2) the review length (in characters).<br> The length feature should be scaled to\n",
    "be between 0 and 1 by dividing by the maximum length. Using the same value of C from the previous\n",
    "question, report the BER of the new classifier (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Implement a complete regularization pipeline with the balanced classifier. Split your test data from above\n",
    "in half so that you have 50%/25%/25% train/validation/test fractions. Consider values of $C$ in the range\n",
    "$\\{10−6, 10−5, 10−4, 10−3\\}$. Report (or plot) the train, validation, and test BER for each value of $C$. Based\n",
    "on these values, which classifier would you select (in terms of generalization performance) and why (1\n",
    "mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **(CSE158 only)** An *ablation study* measures the marginal benefit of various features by re-training the\n",
    "model with one feature ‘ablated’ (i.e., deleted) at a time. Considering each of the three features in your\n",
    "classifier above (i.e., beer style, ratings, and length), report the BER with only the other two features\n",
    "and the third deleted (1 mark).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks (Community Detection):\n",
    "Download the Facebook ego-network data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) How many connected components are in the graph, and how many nodes are in the largest connected\n",
    "component (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we’ll implement a ‘greedy’ version of normalized cuts, using <b><i>just the largest connected component</i></b>\n",
    "found above. First, split it into two equal halves, just by taking the 50% of nodes with the lowest and 50%\n",
    "with the highest IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) What is the normalized-cut cost of the 50/50 split you found above (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll implement our greedy algorithm as follows: during each step, we’ll move one node from one\n",
    "cluster to the other, choosing whichever move *minimizes the resulting normalized cut cost* (in case of a tie, pick\n",
    "the node with the lower ID). Repeat this until the cost can’t be reduced any further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) What are the elements of the split, and what is its normalized cut cost (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
